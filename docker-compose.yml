version: '3.8'
services:
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - crypto-net

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
    networks:
      - crypto-net
    depends_on:
      - zookeeper

  websocket-client:
    build:
      context: ./websocket-client
    container_name: websocket-client
    networks:
      - crypto-net

  spark-master:
    image: bitnami/spark:3
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"
    networks:
      - crypto-net
    depends_on:
      - kafka
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 5

  spark-worker:
    image: bitnami/spark:3
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
      - crypto-net
    depends_on:
      spark-master:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G

  spark-stream-job:
    build:
      ./spark-jobs/stream_processing
    container_name: spark-stream-job
    depends_on:
      spark-master:
        condition: service_healthy
      spark-worker:
        condition: service_started
      kafka:
        condition: service_started
    networks:
      - crypto-net

  spark-batch-job:
    build:
       ./spark-jobs/batch_processing
    container_name: spark-batch-job
    depends_on:
      spark-master:
        condition: service_healthy
      spark-worker:
        condition: service_started
    networks:
      - crypto-net

  

  cassandra:
    image: cassandra:3.11.2
    container_name: cassandra
    ports:
      - "9042:9042"
    environment:
      - "MAX_HEAP_SIZE=256M"
      - "HEAP_NEWSIZE=128M"
    restart: always
    volumes:
      - ./out/cassandra_data:/var/lib/cassandra
    networks:
      - crypto-net
    healthcheck:
      test: ["CMD", "cqlsh", "-u cassandra", "-p cassandra", "-e", "describe keyspaces"]
      interval: 15s
      timeout: 10s
      retries: 10

  cassandra-load-keyspace:
    container_name: cassandra-load-keyspace
    image: cassandra:3.11.2
    depends_on:
      cassandra:
        condition: service_healthy
    volumes:
      - ./cassandra/init.cql:/schema.cql
    command: /bin/bash -c "echo loading cassandra keyspace && cqlsh cassandra -u cassandra -p cassandra -f /schema.cql"
    networks:
      - crypto-net

  fastapi-app:
    build:
      context: ./fastapi-app
    container_name: fastapi-app
    ports:
      - "8000:8000"
    depends_on:
      cassandra:
        condition: service_healthy
    networks:
      - crypto-net

networks:
  crypto-net:
    name: crypto-net
